{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmoNODE import utils\n",
    "from cosmoNODE.loaders import LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data formatted according to https://github.com/YuliaRubanova/latent_ode/issues/2\n",
    "# (record_id, observation_times, values, mask, labels)\n",
    "# working on parse_dataset\n",
    "fluxnet = utils.FluxNet()\n",
    "curve = fluxnet.curves[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(fluxnet, train_size=0.8, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_id, tt, vals, mask, labels = train_data[0]\n",
    "n_samples = len(fluxnet)\n",
    "input_dim = vals.size(-1)\n",
    "\n",
    "batch_size = 30\n",
    "dataset_size_n = 100\n",
    "\n",
    "batch_size = min(min(len(fluxnet), batch_size), dataset_size_n)\n",
    "mins = fluxnet.merged.min()\n",
    "maxes = fluxnet.merged.max()\n",
    "data_max = torch.tensor(maxes.values)\n",
    "data_min = torch.tensor(mins.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_time_collate_fn(batch, device = torch.device(\"cpu\"), data_type = \"train\",\n",
    "    data_min = None, data_max = None):\n",
    "    \"\"\"\n",
    "    Expects a batch of time series data in the form of (record_id, tt, vals, mask, labels) where\n",
    "        - record_id is a patient id\n",
    "        - tt is a 1-dimensional tensor containing T time values of observations.\n",
    "        - vals is a (T, D) tensor containing observed values for D variables.\n",
    "        - mask is a (T, D) tensor containing 1 where values were observed and 0 otherwise.\n",
    "        - labels is a list of labels for the current patient, if labels are available. Otherwise None.\n",
    "    Returns:\n",
    "        combined_tt: The union of all time observations.\n",
    "        combined_vals: (M, T, D) tensor containing the observed values.\n",
    "        combined_mask: (M, T, D) tensor containing 1 where values were observed and 0 otherwise.\n",
    "    \"\"\"\n",
    "    D = batch[0][2].shape[1]\n",
    "    combined_tt, inverse_indices = torch.unique(torch.cat([ex[1] for ex in batch]), sorted=True, return_inverse=True)\n",
    "    combined_tt = combined_tt.to(device)\n",
    "\n",
    "    offset = 0\n",
    "    combined_vals = torch.zeros([len(batch), len(combined_tt), D]).to(device)\n",
    "    combined_mask = torch.zeros([len(batch), len(combined_tt), D]).to(device)\n",
    "\n",
    "    combined_labels = None\n",
    "    N_labels = 14\n",
    "\n",
    "    combined_labels = torch.zeros(len(batch), N_labels) + torch.tensor(float('nan'))\n",
    "    combined_labels = combined_labels.to(device = device)\n",
    "\n",
    "    for b, (record_id, tt, vals, mask, labels) in enumerate(batch):\n",
    "        tt = tt.float()\n",
    "        vals = vals.float()\n",
    "        mask = mask.float()\n",
    "        tt = tt.to(device)\n",
    "        vals = vals.to(device)\n",
    "        mask = mask.to(device)\n",
    "        if labels is not None:\n",
    "            labels = labels.to(device)\n",
    "\n",
    "        indices = inverse_indices[offset:offset + len(tt)]\n",
    "        offset += len(tt)\n",
    "\n",
    "        combined_vals[b, indices] = vals\n",
    "        combined_mask[b, indices] = mask\n",
    "\n",
    "        if labels is not None:\n",
    "            combined_labels[b] = labels\n",
    "\n",
    "    # combined_vals, _, _ = utils.normalize_masked_data(combined_vals, combined_mask,\n",
    "    # \tatt_min = data_min, att_max = data_max)\n",
    "\n",
    "    if torch.max(combined_tt) != 0.:\n",
    "        combined_tt = combined_tt / torch.max(combined_tt)\n",
    "\n",
    "    data_dict = {\n",
    "        \"data\": combined_vals,\n",
    "        \"time_steps\": combined_tt,\n",
    "        \"mask\": combined_mask,\n",
    "        \"labels\": combined_labels[:,4]}\n",
    "\n",
    "    # data_dict = utils.split_and_subsample_batch(data_dict, args, data_type = data_type)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_min, data_max = get_data_min_max(total_dataset)\n",
    "batch = fluxnet[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size= batch_size, shuffle=False, \n",
    "            collate_fn= lambda batch: variable_time_collate_fn(batch, data_type = \"train\",\n",
    "                data_min = data_min, data_max = data_max))\n",
    "test_dataloader = DataLoader(test_data, batch_size = n_samples, shuffle=False, \n",
    "            collate_fn= lambda batch: variable_time_collate_fn(batch, data_type = \"test\",\n",
    "                data_min = data_min, data_max = data_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = batch[0][2].shape[1]\n",
    "combined_tt, inverse_indices = torch.unique(torch.cat([ex[1] for ex in batch]), sorted=True, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1638"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(combined_tt)\n",
    "len(combined_tt)\n",
    "# print(inverse_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.5030e+07,  5.0000e+00, -6.7657e+01,  ...,  7.5000e-03,\n",
      "           3.9031e+01,  4.5000e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]]), 'time_steps': tensor([0.9820, 0.9820, 0.9820,  ..., 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64), 'mask': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    if i == 1:\n",
    "        break\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = fluxnet.params\n",
    "data_objects = {\"dataset_obj\": fluxnet, \n",
    "            \"train_dataloader\": utils.inf_generator(train_dataloader), \n",
    "            \"test_dataloader\": utils.inf_generator(test_dataloader),\n",
    "            \"input_dim\": input_dim,\n",
    "            \"n_train_batches\": len(train_dataloader),\n",
    "            \"n_test_batches\": len(test_dataloader),\n",
    "            \"attr\": attr_names, #optional\n",
    "            \"classif_per_tp\": False, #optional\n",
    "            \"n_labels\": 14} #optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_models main adaptation\n",
    "\n",
    "data_obj = data_objects\n",
    "input_dim = data_obj['input_dim']\n",
    "n_labels = data_obj['n_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network_weights(net, std = 0.1):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, mean=0, std=std)\n",
    "            nn.init.constant_(m.bias, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_z0_ODE_RNN(nn.Module):\n",
    "    # Derive z0 by running ode backwards.\n",
    "    # For every y_i we have two versions: encoded from data and derived from ODE by running it backwards from t_i+1 to t_i\n",
    "    # Compute a weighted sum of y_i from data and y_i from ode. Use weighted y_i as an initial value for ODE runing from t_i to t_i-1\n",
    "    # Continue until we get to z0\n",
    "    def __init__(self, latent_dim, input_dim, z0_diffeq_solver = None, \n",
    "        z0_dim = None, GRU_update = None, \n",
    "        n_gru_units = 100, \n",
    "        device = torch.device(\"cpu\")):\n",
    "\n",
    "        super(Encoder_z0_ODE_RNN, self).__init__()\n",
    "\n",
    "        if z0_dim is None:\n",
    "            self.z0_dim = latent_dim\n",
    "        else:\n",
    "            self.z0_dim = z0_dim\n",
    "\n",
    "        if GRU_update is None:\n",
    "            self.GRU_update = GRU_unit(latent_dim, input_dim, \n",
    "                n_units = n_gru_units, \n",
    "                device=device).to(device)\n",
    "        else:\n",
    "            self.GRU_update = GRU_update\n",
    "\n",
    "        self.z0_diffeq_solver = z0_diffeq_solver\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.device = device\n",
    "        self.extra_info = None\n",
    "\n",
    "        self.transform_z0 = nn.Sequential(\n",
    "           nn.Linear(latent_dim * 2, 100),\n",
    "           nn.Tanh(),\n",
    "           nn.Linear(100, self.z0_dim * 2),)\n",
    "        utils.init_network_weights(self.transform_z0)\n",
    "\n",
    "\n",
    "    def forward(self, data, time_steps, run_backwards = True, save_info = False):\n",
    "        # data, time_steps -- observations and their time stamps\n",
    "        # IMPORTANT: assumes that 'data' already has mask concatenated to it \n",
    "        assert(not torch.isnan(data).any())\n",
    "        assert(not torch.isnan(time_steps).any())\n",
    "\n",
    "        n_traj, n_tp, n_dims = data.size()\n",
    "        if len(time_steps) == 1:\n",
    "            prev_y = torch.zeros((1, n_traj, self.latent_dim)).to(self.device)\n",
    "            prev_std = torch.zeros((1, n_traj, self.latent_dim)).to(self.device)\n",
    "\n",
    "            xi = data[:,0,:].unsqueeze(0)\n",
    "\n",
    "            last_yi, last_yi_std = self.GRU_update(prev_y, prev_std, xi)\n",
    "            extra_info = None\n",
    "        else:\n",
    "\n",
    "            last_yi, last_yi_std, _, extra_info = self.run_odernn(\n",
    "                data, time_steps, run_backwards = run_backwards,\n",
    "                save_info = save_info)\n",
    "\n",
    "        means_z0 = last_yi.reshape(1, n_traj, self.latent_dim)\n",
    "        std_z0 = last_yi_std.reshape(1, n_traj, self.latent_dim)\n",
    "\n",
    "        mean_z0, std_z0 = utils.split_last_dim( self.transform_z0( torch.cat((means_z0, std_z0), -1)))\n",
    "        std_z0 = std_z0.abs()\n",
    "        if save_info:\n",
    "            self.extra_info = extra_info\n",
    "\n",
    "        return mean_z0, std_z0\n",
    "\n",
    "\n",
    "    def run_odernn(self, data, time_steps, \n",
    "        run_backwards = True, save_info = False):\n",
    "        # IMPORTANT: assumes that 'data' already has mask concatenated to it \n",
    "\n",
    "        n_traj, n_tp, n_dims = data.size()\n",
    "        extra_info = []\n",
    "\n",
    "        t0 = time_steps[-1]\n",
    "        if run_backwards:\n",
    "            t0 = time_steps[0]\n",
    "\n",
    "        device = get_device(data)\n",
    "\n",
    "        prev_y = torch.zeros((1, n_traj, self.latent_dim)).to(device)\n",
    "        prev_std = torch.zeros((1, n_traj, self.latent_dim)).to(device)\n",
    "\n",
    "        prev_t, t_i = time_steps[-1] + 0.01,  time_steps[-1]\n",
    "\n",
    "        interval_length = time_steps[-1] - time_steps[0]\n",
    "        minimum_step = interval_length / 50\n",
    "\n",
    "        #print(\"minimum step: {}\".format(minimum_step))\n",
    "\n",
    "        assert(not torch.isnan(data).any())\n",
    "        assert(not torch.isnan(time_steps).any())\n",
    "\n",
    "        latent_ys = []\n",
    "        # Run ODE backwards and combine the y(t) estimates using gating\n",
    "        time_points_iter = range(0, len(time_steps))\n",
    "        if run_backwards:\n",
    "            time_points_iter = reversed(time_points_iter)\n",
    "\n",
    "        for i in time_points_iter:\n",
    "            if (prev_t - t_i) < minimum_step:\n",
    "                time_points = torch.stack((prev_t, t_i))\n",
    "                inc = self.z0_diffeq_solver.ode_func(prev_t, prev_y) * (t_i - prev_t)\n",
    "\n",
    "                assert(not torch.isnan(inc).any())\n",
    "\n",
    "                ode_sol = prev_y + inc\n",
    "                ode_sol = torch.stack((prev_y, ode_sol), 2).to(device)\n",
    "\n",
    "                assert(not torch.isnan(ode_sol).any())\n",
    "            else:\n",
    "                n_intermediate_tp = max(2, ((prev_t - t_i) / minimum_step).int())\n",
    "\n",
    "                time_points = utils.linspace_vector(prev_t, t_i, n_intermediate_tp)\n",
    "                ode_sol = self.z0_diffeq_solver(prev_y, time_points)\n",
    "\n",
    "                assert(not torch.isnan(ode_sol).any())\n",
    "\n",
    "            if torch.mean(ode_sol[:, :, 0, :]  - prev_y) >= 0.001:\n",
    "                print(\"Error: first point of the ODE is not equal to initial value\")\n",
    "                print(torch.mean(ode_sol[:, :, 0, :]  - prev_y))\n",
    "                exit()\n",
    "            #assert(torch.mean(ode_sol[:, :, 0, :]  - prev_y) < 0.001)\n",
    "\n",
    "            yi_ode = ode_sol[:, :, -1, :]\n",
    "            xi = data[:,i,:].unsqueeze(0)\n",
    "\n",
    "            yi, yi_std = self.GRU_update(yi_ode, prev_std, xi)\n",
    "\n",
    "            prev_y, prev_std = yi, yi_std\t\t\t\n",
    "            prev_t, t_i = time_steps[i],  time_steps[i-1]\n",
    "\n",
    "            latent_ys.append(yi)\n",
    "\n",
    "            if save_info:\n",
    "                d = {\"yi_ode\": yi_ode.detach(), #\"yi_from_data\": yi_from_data,\n",
    "                     \"yi\": yi.detach(), \"yi_std\": yi_std.detach(), \n",
    "                     \"time_points\": time_points.detach(), \"ode_sol\": ode_sol.detach()}\n",
    "                extra_info.append(d)\n",
    "\n",
    "        latent_ys = torch.stack(latent_ys, 1)\n",
    "\n",
    "        assert(not torch.isnan(yi).any())\n",
    "        assert(not torch.isnan(yi_std).any())\n",
    "\n",
    "        return yi, yi_std, latent_ys, extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffeqSolver(nn.Module):\n",
    "    def __init__(self, input_dim, ode_func, method, latents, \n",
    "            odeint_rtol = 1e-4, odeint_atol = 1e-5, device = torch.device(\"cpu\")):\n",
    "        super(DiffeqSolver, self).__init__()\n",
    "\n",
    "        self.ode_method = method\n",
    "        self.latents = latents\t\t\n",
    "        self.device = device\n",
    "        self.ode_func = ode_func\n",
    "\n",
    "        self.odeint_rtol = odeint_rtol\n",
    "        self.odeint_atol = odeint_atol\n",
    "\n",
    "    def forward(self, first_point, time_steps_to_predict, backwards = False):\n",
    "        \"\"\"\n",
    "        # Decode the trajectory through ODE Solver\n",
    "        \"\"\"\n",
    "        n_traj_samples, n_traj = first_point.size()[0], first_point.size()[1]\n",
    "        n_dims = first_point.size()[-1]\n",
    "\n",
    "        pred_y = odeint(self.ode_func, first_point, time_steps_to_predict, \n",
    "            rtol=self.odeint_rtol, atol=self.odeint_atol, method = self.ode_method)\n",
    "        pred_y = pred_y.permute(1,2,0,3)\n",
    "\n",
    "        assert(torch.mean(pred_y[:, :, 0, :]  - first_point) < 0.001)\n",
    "        assert(pred_y.size()[0] == n_traj_samples)\n",
    "        assert(pred_y.size()[1] == n_traj)\n",
    "\n",
    "        return pred_y\n",
    "\n",
    "    def sample_traj_from_prior(self, starting_point_enc, time_steps_to_predict, \n",
    "        n_traj_samples = 1):\n",
    "        \"\"\"\n",
    "        # Decode the trajectory through ODE Solver using samples from the prior\n",
    "        time_steps_to_predict: time steps at which we want to sample the new trajectory\n",
    "        \"\"\"\n",
    "        func = self.ode_func.sample_next_point_from_prior\n",
    "\n",
    "        pred_y = odeint(func, starting_point_enc, time_steps_to_predict, \n",
    "            rtol=self.odeint_rtol, atol=self.odeint_atol, method = self.ode_method)\n",
    "        # shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
    "        pred_y = pred_y.permute(1,2,0,3)\n",
    "        return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, ode_func_net, device = torch.device(\"cpu\")):\n",
    "        \"\"\"\n",
    "        input_dim: dimensionality of the input\n",
    "        latent_dim: dimensionality used for ODE. Analog of a continous latent state\n",
    "        \"\"\"\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.device = device\n",
    "\n",
    "        init_network_weights(ode_func_net)\n",
    "        self.gradient_net = ode_func_net\n",
    "\n",
    "    def forward(self, t_local, y, backwards = False):\n",
    "        \"\"\"\n",
    "        Perform one step in solving ODE. Given current data point y and current time point t_local, returns gradient dy/dt at this time point\n",
    "        t_local: current time point\n",
    "        y: value at the current time point\n",
    "        \"\"\"\n",
    "        grad = self.get_ode_gradient_nn(t_local, y)\n",
    "        if backwards:\n",
    "            grad = -grad\n",
    "        return grad\n",
    "\n",
    "    def get_ode_gradient_nn(self, t_local, y):\n",
    "        return self.gradient_net(y)\n",
    "\n",
    "    def sample_next_point_from_prior(self, t_local, y):\n",
    "        \"\"\"\n",
    "        t_local: current time point\n",
    "        y: value at the current time point\n",
    "        \"\"\"\n",
    "        return self.get_ode_gradient_nn(t_local, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Baseline(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, \n",
    "        z0_prior, device,\n",
    "        obsrv_std = 0.01, \n",
    "        use_binary_classif = False,\n",
    "        classif_per_tp = False,\n",
    "        use_poisson_proc = False,\n",
    "        linear_classifier = False,\n",
    "        n_labels = 1,\n",
    "        train_classif_w_reconstr = False):\n",
    "\n",
    "        super(VAE_Baseline, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = device\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        self.obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
    "\n",
    "        self.z0_prior = z0_prior\n",
    "        self.use_binary_classif = use_binary_classif\n",
    "        self.classif_per_tp = classif_per_tp\n",
    "        self.use_poisson_proc = use_poisson_proc\n",
    "        self.linear_classifier = linear_classifier\n",
    "        self.train_classif_w_reconstr = train_classif_w_reconstr\n",
    "\n",
    "        z0_dim = latent_dim\n",
    "        if use_poisson_proc:\n",
    "            z0_dim += latent_dim\n",
    "\n",
    "        if use_binary_classif: \n",
    "            if linear_classifier:\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Linear(z0_dim, n_labels))\n",
    "            else:\n",
    "                self.classifier = create_classifier(z0_dim, n_labels)\n",
    "            utils.init_network_weights(self.classifier)\n",
    "\n",
    "\n",
    "    def get_gaussian_likelihood(self, truth, pred_y, mask = None):\n",
    "        # pred_y shape [n_traj_samples, n_traj, n_tp, n_dim]\n",
    "        # truth shape  [n_traj, n_tp, n_dim]\n",
    "        n_traj, n_tp, n_dim = truth.size()\n",
    "\n",
    "        # Compute likelihood of the data under the predictions\n",
    "        truth_repeated = truth.repeat(pred_y.size(0), 1, 1, 1)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(pred_y.size(0), 1, 1, 1)\n",
    "        log_density_data = masked_gaussian_log_density(pred_y, truth_repeated, \n",
    "            obsrv_std = self.obsrv_std, mask = mask)\n",
    "        log_density_data = log_density_data.permute(1,0)\n",
    "        log_density = torch.mean(log_density_data, 1)\n",
    "\n",
    "        # shape: [n_traj_samples]\n",
    "        return log_density\n",
    "\n",
    "\n",
    "    def get_mse(self, truth, pred_y, mask = None):\n",
    "        # pred_y shape [n_traj_samples, n_traj, n_tp, n_dim]\n",
    "        # truth shape  [n_traj, n_tp, n_dim]\n",
    "        n_traj, n_tp, n_dim = truth.size()\n",
    "\n",
    "        # Compute likelihood of the data under the predictions\n",
    "        truth_repeated = truth.repeat(pred_y.size(0), 1, 1, 1)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(pred_y.size(0), 1, 1, 1)\n",
    "\n",
    "        # Compute likelihood of the data under the predictions\n",
    "        log_density_data = compute_mse(pred_y, truth_repeated, mask = mask)\n",
    "        # shape: [1]\n",
    "        return torch.mean(log_density_data)\n",
    "\n",
    "\n",
    "    def compute_all_losses(self, batch_dict, n_traj_samples = 1, kl_coef = 1.):\n",
    "        # Condition on subsampled points\n",
    "        # Make predictions for all the points\n",
    "        pred_y, info = self.get_reconstruction(batch_dict[\"tp_to_predict\"], \n",
    "            batch_dict[\"observed_data\"], batch_dict[\"observed_tp\"], \n",
    "            mask = batch_dict[\"observed_mask\"], n_traj_samples = n_traj_samples,\n",
    "            mode = batch_dict[\"mode\"])\n",
    "\n",
    "        #print(\"get_reconstruction done -- computing likelihood\")\n",
    "        fp_mu, fp_std, fp_enc = info[\"first_point\"]\n",
    "        fp_std = fp_std.abs()\n",
    "        fp_distr = Normal(fp_mu, fp_std)\n",
    "\n",
    "        assert(torch.sum(fp_std < 0) == 0.)\n",
    "\n",
    "        kldiv_z0 = kl_divergence(fp_distr, self.z0_prior)\n",
    "\n",
    "        if torch.isnan(kldiv_z0).any():\n",
    "            print(fp_mu)\n",
    "            print(fp_std)\n",
    "            raise Exception(\"kldiv_z0 is Nan!\")\n",
    "\n",
    "        # Mean over number of latent dimensions\n",
    "        # kldiv_z0 shape: [n_traj_samples, n_traj, n_latent_dims] if prior is a mixture of gaussians (KL is estimated)\n",
    "        # kldiv_z0 shape: [1, n_traj, n_latent_dims] if prior is a standard gaussian (KL is computed exactly)\n",
    "        # shape after: [n_traj_samples]\n",
    "        kldiv_z0 = torch.mean(kldiv_z0,(1,2))\n",
    "\n",
    "        # Compute likelihood of all the points\n",
    "        rec_likelihood = self.get_gaussian_likelihood(\n",
    "            batch_dict[\"data_to_predict\"], pred_y,\n",
    "            mask = batch_dict[\"mask_predicted_data\"])\n",
    "\n",
    "        mse = self.get_mse(\n",
    "            batch_dict[\"data_to_predict\"], pred_y,\n",
    "            mask = batch_dict[\"mask_predicted_data\"])\n",
    "\n",
    "        pois_log_likelihood = torch.Tensor([0.]).to(get_device(batch_dict[\"data_to_predict\"]))\n",
    "        if self.use_poisson_proc:\n",
    "            pois_log_likelihood = compute_poisson_proc_likelihood(\n",
    "                batch_dict[\"data_to_predict\"], pred_y, \n",
    "                info, mask = batch_dict[\"mask_predicted_data\"])\n",
    "            # Take mean over n_traj\n",
    "            pois_log_likelihood = torch.mean(pois_log_likelihood, 1)\n",
    "\n",
    "        ################################\n",
    "        # Compute CE loss for binary classification on Physionet\n",
    "        device = get_device(batch_dict[\"data_to_predict\"])\n",
    "        ce_loss = torch.Tensor([0.]).to(device)\n",
    "        if (batch_dict[\"labels\"] is not None) and self.use_binary_classif:\n",
    "\n",
    "            if (batch_dict[\"labels\"].size(-1) == 1) or (len(batch_dict[\"labels\"].size()) == 1):\n",
    "                ce_loss = compute_binary_CE_loss(\n",
    "                    info[\"label_predictions\"], \n",
    "                    batch_dict[\"labels\"])\n",
    "            else:\n",
    "                ce_loss = compute_multiclass_CE_loss(\n",
    "                    info[\"label_predictions\"], \n",
    "                    batch_dict[\"labels\"],\n",
    "                    mask = batch_dict[\"mask_predicted_data\"])\n",
    "\n",
    "        # IWAE loss\n",
    "        loss = - torch.logsumexp(rec_likelihood + kl_coef * kldiv_z0,0)\n",
    "        if torch.isnan(loss):\n",
    "            loss = - torch.mean(rec_likelihood + kl_coef * kldiv_z0,0)\n",
    "\n",
    "        if self.use_poisson_proc:\n",
    "            loss = loss - 0.1 * pois_log_likelihood \n",
    "\n",
    "        if self.use_binary_classif:\n",
    "            if self.train_classif_w_reconstr:\n",
    "                loss = loss +  ce_loss * 100\n",
    "            else:\n",
    "                loss =  ce_loss\n",
    "\n",
    "        results = {}\n",
    "        results[\"loss\"] = torch.mean(loss)\n",
    "        results[\"likelihood\"] = torch.mean(rec_likelihood).detach()\n",
    "        results[\"mse\"] = torch.mean(mse).detach()\n",
    "        results[\"pois_likelihood\"] = torch.mean(pois_log_likelihood).detach()\n",
    "        results[\"ce_loss\"] = torch.mean(ce_loss).detach()\n",
    "        results[\"kl_first_p\"] =  torch.mean(kldiv_z0).detach()\n",
    "        results[\"std_first_p\"] = torch.mean(fp_std).detach()\n",
    "\n",
    "        if batch_dict[\"labels\"] is not None and self.use_binary_classif:\n",
    "            results[\"label_predictions\"] = info[\"label_predictions\"].detach()\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentODE(VAE_Baseline):\n",
    "    def __init__(self, input_dim, latent_dim, encoder_z0, decoder, diffeq_solver, \n",
    "        z0_prior, device, obsrv_std = None, \n",
    "        use_binary_classif = False, use_poisson_proc = False,\n",
    "        linear_classifier = False,\n",
    "        classif_per_tp = False,\n",
    "        n_labels = 1,\n",
    "        train_classif_w_reconstr = False):\n",
    "\n",
    "        super(LatentODE, self).__init__(\n",
    "            input_dim = input_dim, latent_dim = latent_dim, \n",
    "            z0_prior = z0_prior, \n",
    "            device = device, obsrv_std = obsrv_std, \n",
    "            use_binary_classif = use_binary_classif,\n",
    "            classif_per_tp = classif_per_tp, \n",
    "            linear_classifier = linear_classifier,\n",
    "            use_poisson_proc = use_poisson_proc,\n",
    "            n_labels = n_labels,\n",
    "            train_classif_w_reconstr = train_classif_w_reconstr)\n",
    "\n",
    "        self.encoder_z0 = encoder_z0\n",
    "        self.diffeq_solver = diffeq_solver\n",
    "        self.decoder = decoder\n",
    "        self.use_poisson_proc = use_poisson_proc\n",
    "\n",
    "    def get_reconstruction(self, time_steps_to_predict, truth, truth_time_steps, \n",
    "        mask = None, n_traj_samples = 1, run_backwards = True, mode = None):\n",
    "\n",
    "        if isinstance(self.encoder_z0, Encoder_z0_ODE_RNN) or \\\n",
    "            isinstance(self.encoder_z0, Encoder_z0_RNN):\n",
    "\n",
    "            truth_w_mask = truth\n",
    "            if mask is not None:\n",
    "                truth_w_mask = torch.cat((truth, mask), -1)\n",
    "            first_point_mu, first_point_std = self.encoder_z0(\n",
    "                truth_w_mask, truth_time_steps, run_backwards = run_backwards)\n",
    "\n",
    "            means_z0 = first_point_mu.repeat(n_traj_samples, 1, 1)\n",
    "            sigma_z0 = first_point_std.repeat(n_traj_samples, 1, 1)\n",
    "            first_point_enc = utils.sample_standard_gaussian(means_z0, sigma_z0)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Unknown encoder type {}\".format(type(self.encoder_z0).__name__))\n",
    "\n",
    "        first_point_std = first_point_std.abs()\n",
    "        assert(torch.sum(first_point_std < 0) == 0.)\n",
    "\n",
    "        if self.use_poisson_proc:\n",
    "            n_traj_samples, n_traj, n_dims = first_point_enc.size()\n",
    "            # append a vector of zeros to compute the integral of lambda\n",
    "            zeros = torch.zeros([n_traj_samples, n_traj,self.input_dim]).to(get_device(truth))\n",
    "            first_point_enc_aug = torch.cat((first_point_enc, zeros), -1)\n",
    "            means_z0_aug = torch.cat((means_z0, zeros), -1)\n",
    "        else:\n",
    "            first_point_enc_aug = first_point_enc\n",
    "            means_z0_aug = means_z0\n",
    "\n",
    "        assert(not torch.isnan(time_steps_to_predict).any())\n",
    "        assert(not torch.isnan(first_point_enc).any())\n",
    "        assert(not torch.isnan(first_point_enc_aug).any())\n",
    "\n",
    "        # Shape of sol_y [n_traj_samples, n_samples, n_timepoints, n_latents]\n",
    "        sol_y = self.diffeq_solver(first_point_enc_aug, time_steps_to_predict)\n",
    "\n",
    "        if self.use_poisson_proc:\n",
    "            sol_y, log_lambda_y, int_lambda, _ = self.diffeq_solver.ode_func.extract_poisson_rate(sol_y)\n",
    "\n",
    "            assert(torch.sum(int_lambda[:,:,0,:]) == 0.)\n",
    "            assert(torch.sum(int_lambda[0,0,-1,:] <= 0) == 0.)\n",
    "\n",
    "        pred_x = self.decoder(sol_y)\n",
    "\n",
    "        all_extra_info = {\n",
    "            \"first_point\": (first_point_mu, first_point_std, first_point_enc),\n",
    "            \"latent_traj\": sol_y.detach()\n",
    "        }\n",
    "\n",
    "        if self.use_poisson_proc:\n",
    "            # intergral of lambda from the last step of ODE Solver\n",
    "            all_extra_info[\"int_lambda\"] = int_lambda[:,:,-1,:]\n",
    "            all_extra_info[\"log_lambda_y\"] = log_lambda_y\n",
    "\n",
    "        if self.use_binary_classif:\n",
    "            if self.classif_per_tp:\n",
    "                all_extra_info[\"label_predictions\"] = self.classifier(sol_y)\n",
    "            else:\n",
    "                all_extra_info[\"label_predictions\"] = self.classifier(first_point_enc).squeeze(-1)\n",
    "\n",
    "        return pred_x, all_extra_info\n",
    "\n",
    "\n",
    "    def sample_traj_from_prior(self, time_steps_to_predict, n_traj_samples = 1):\n",
    "        # input_dim = starting_point.size()[-1]\n",
    "        # starting_point = starting_point.view(1,1,input_dim)\n",
    "\n",
    "        # Sample z0 from prior\n",
    "        starting_point_enc = self.z0_prior.sample([n_traj_samples, 1, self.latent_dim]).squeeze(-1)\n",
    "\n",
    "        starting_point_enc_aug = starting_point_enc\n",
    "        if self.use_poisson_proc:\n",
    "            n_traj_samples, n_traj, n_dims = starting_point_enc.size()\n",
    "            # append a vector of zeros to compute the integral of lambda\n",
    "            zeros = torch.zeros(n_traj_samples, n_traj,self.input_dim).to(self.device)\n",
    "            starting_point_enc_aug = torch.cat((starting_point_enc, zeros), -1)\n",
    "\n",
    "        sol_y = self.diffeq_solver.sample_traj_from_prior(starting_point_enc_aug, time_steps_to_predict, \n",
    "            n_traj_samples = 3)\n",
    "\n",
    "        if self.use_poisson_proc:\n",
    "            sol_y, log_lambda_y, int_lambda, _ = self.diffeq_solver.ode_func.extract_poisson_rate(sol_y)\n",
    "\n",
    "        return self.decoder(sol_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LatentODE_model(input_dim, latents, rec_dims, z0_prior, obsrv_std, device, \n",
    "    classif_per_tp = False, n_labels = 1):\n",
    "\n",
    "    dim = latents\n",
    "    ode_func_net = create_net(dim, latents, \n",
    "        n_layers = 1, n_units = 100, nonlinear = nn.Tanh)\n",
    "\n",
    "    gen_ode_func = ODEFunc(\n",
    "        input_dim = input_dim, \n",
    "        latent_dim = latents, \n",
    "        ode_func_net = ode_func_net,\n",
    "        device = device).to(device)\n",
    "\n",
    "    n_rec_dims = rec_dims\n",
    "    enc_input_dim = int(input_dim) * 2 # we concatenate the mask\n",
    "    gen_data_dim = input_dim\n",
    "\n",
    "    z0_dim = latents\n",
    "\n",
    "    ode_func_net = create_net(n_rec_dims, n_rec_dims, \n",
    "        n_layers = 1, n_units = 100, nonlinear = nn.Tanh)\n",
    "\n",
    "    rec_ode_func = ODEFunc(\n",
    "        input_dim = enc_input_dim, \n",
    "        latent_dim = n_rec_dims,\n",
    "        ode_func_net = ode_func_net,\n",
    "        device = device).to(device)\n",
    "\n",
    "    z0_diffeq_solver = DiffeqSolver(enc_input_dim, rec_ode_func, \"euler\", latents, \n",
    "        odeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\n",
    "    encoder_z0 = Encoder_z0_ODE_RNN(n_rec_dims, enc_input_dim, z0_diffeq_solver, \n",
    "        z0_dim = z0_dim, n_gru_units = 100, device = device).to(device)\n",
    "\n",
    "    decoder = Decoder(latents, gen_data_dim).to(device)\n",
    "\n",
    "    diffeq_solver = DiffeqSolver(gen_data_dim, gen_ode_func, 'dopri5', latents, \n",
    "        odeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\n",
    "    model = LatentODE(\n",
    "        input_dim = gen_data_dim, \n",
    "        latent_dim = latents, \n",
    "        encoder_z0 = encoder_z0, \n",
    "        decoder = decoder, \n",
    "        diffeq_solver = diffeq_solver, \n",
    "        z0_prior = z0_prior, \n",
    "        device = device,\n",
    "        obsrv_std = obsrv_std,\n",
    "        use_poisson_proc = False, \n",
    "        use_binary_classif = False,\n",
    "        linear_classifier = args.linear_classif,\n",
    "        classif_per_tp = classif_per_tp,\n",
    "        n_labels = n_labels,\n",
    "        train_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "        ).to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net(n_inputs, n_outputs, n_layers = 1, \n",
    "    n_units = 100, nonlinear = nn.Tanh):\n",
    "    layers = [nn.Linear(n_inputs, n_units)]\n",
    "    for i in range(n_layers):\n",
    "        layers.append(nonlinear())\n",
    "        layers.append(nn.Linear(n_units, n_units))\n",
    "\n",
    "    layers.append(nonlinear())\n",
    "    layers.append(nn.Linear(n_units, n_outputs))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRU_unit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-5e9a75f049ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model = create_LatentODE_model(input_dim, latents=6, rec_dims=20, z0_prior=z0_prior, obsrv_std=obsrv_std, device=device, \n\u001b[0;32m----> 8\u001b[0;31m     classif_per_tp=False, n_labels = 14)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-120-774b8c04ed6f>\u001b[0m in \u001b[0;36mcreate_LatentODE_model\u001b[0;34m(input_dim, latents, rec_dims, z0_prior, obsrv_std, device, classif_per_tp, n_labels)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     encoder_z0 = Encoder_z0_ODE_RNN(n_rec_dims, enc_input_dim, z0_diffeq_solver, \n\u001b[0;32m---> 33\u001b[0;31m         z0_dim = z0_dim, n_gru_units = 100, device = device).to(device)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_data_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-ceb4ab365186>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_dim, input_dim, z0_diffeq_solver, z0_dim, GRU_update, n_gru_units, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mGRU_update\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             self.GRU_update = GRU_unit(latent_dim, input_dim, \n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mn_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_gru_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 device=device).to(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GRU_unit' is not defined"
     ]
    }
   ],
   "source": [
    "latents = 6\n",
    "obsrv_std = 0.01\n",
    "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
    "\n",
    "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
    "\n",
    "model = create_LatentODE_model(input_dim, latents=6, rec_dims=20, z0_prior=z0_prior, obsrv_std=obsrv_std, device=device, \n",
    "    classif_per_tp=False, n_labels = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
